---
title: "Homework 6"
author: "Mia Isaacs"
date: "2024-12-01"
output: github_document
---

### load libraries
```{r}
library(tidyverse)
library(modelr)
library(rnoaa)

set.seed(123)
```

## Problem 1
### load and clean data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### draw bootstrap sample
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```

### generate 5000 samples
```{r}
boot_results = 
  tibble(
    strap_id = 1:5000
  ) |> 
  mutate(
    strap_sample = map(strap_id, ~ boot_sample(weather_df)),
    models = map(strap_sample, ~ lm(tmax ~ tmin, data = .x)),
    model_summaries = map(models, broom::glance),
    coefficients = map(models, broom::tidy)
  ) |> 
  unnest(model_summaries, names_sep = "_summary") |> 
  unnest(coefficients, names_sep = "_coef") |> 
  janitor::clean_names() |> 
  rename_with(
    ~ gsub("^model_summaries_", "", .), 
    starts_with("model_summaries_")    
  )
```

### produce estimates
```{r}
bootstrap_estimates = 
  boot_results |> 
  group_by(strap_id) |> 
  summarize(
    r_squared = unique(summaryr_squared),  
    log_beta0_beta1 = log(prod(coefficients_coefestimate))
  )
```

### plot distributions
```{r}
# R-squared distribution
bootstrap_estimates |> 
  ggplot(aes(x = r_squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of R-squared",
    x = "R-squared",
    y = "Density"
  )

# log(beta0 * beta1) distribution
bootstrap_estimates |> 
  ggplot(aes(x = log_beta0_beta1)) +
  geom_density(fill = "green", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of log(beta0 * beta1)",
    x = "log(beta0 * beta1)",
    y = "Density"
  )
```

The distributions of r-squared and log(beta0*beta1) in our sample both appear to be approximately normal.

### compute confidence intervals
```{r}
ci_results = 
  bootstrap_estimates |> 
  reframe(
    r2_ci_lower = quantile(r_squared, 0.025),
    r2_ci_upper = quantile(r_squared, 0.975),
    log_beta_ci_lower = quantile(log_beta0_beta1, 0.025),
    log_beta_ci_upper = quantile(log_beta0_beta1, 0.975)
  )
```

## Problem 2

### load and clean data
```{r}
homicide_data = read_csv("data/homicide-data.csv") |> 
  mutate(
    city_state = paste(city, state, sep = ", "),
    solved = ifelse(disposition %in% c("Closed by arrest", "Closed without arrest"), 1, 0),
    victim_age = as.numeric(victim_age)
  ) |> 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

### logistic regression for Baltimore
```{r}
baltimore_data <- homicide_data |> 
  filter(city_state == "Baltimore, MD")

baltimore_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_data,
  family = binomial
)
```

### obtain OR for male vs. female
```{r}
baltimore_results <- baltimore_fit |> 
  broom::tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale")

baltimore_results
```

### logistic regression for all cities
```{r}
city_fit_results <- homicide_data |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    model = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial
    )),
    results = map(model, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |> 
  select(city_state, results) |> 
  unnest(results) |> 
  filter(term == "victim_sexMale") |> 
  arrange(estimate)

city_fit_results
```

### plot with ORs and CIs for each city
```{r}
city_fit_results |> 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Adjusted ORs for Solving Homicides by City",
    x = "City",
    y = "Adjusted Odds Ratio (Male vs. Female)"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

For most cities, the adjusted OR for solving homicides comparing males to females is below 1, indicating that male homicide victims are less likely to have their attacker arrested. The odds of having a closed homicide case for males are <1 times the odds of having a closed homicide case for females for all cities in this dataset except Stockton, CA, Minneapolis, MN, and Fresno, CA.

## Problem 3

### load and clean data
```{r}
birthweight_df = read_csv("data/birthweight.csv") |> 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace)
         )

summary(birthweight_df)
```

### look at data
```{r}
ggplot(birthweight_df, aes(x = bwt, y = blength)) + 
  geom_point() + 
  theme_minimal()
```

### propose model
```{r}
hypothetical_model <- lm(bwt ~ blength + bhead + babysex + gaweeks + delwt + fincome + 
                            smoken + wtgain + momage + mheight + parity, data = birthweight_df)

birthweight_df |> 
  add_predictions(hypothetical_model) |>
  add_residuals(hypothetical_model) |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", color = "red") + 
  theme_minimal() +
  labs(x = "Fitted Values", y = "Residuals")
```

My modeling process was based on hypothesized factors that may influence infant birthweight. Of the predictors in this dataset, I felt that baby length, head circumference, sex, gestational age, and mother's weight at delivery, income, smoking status, age, height, and prior live births would be most likely to explain differences in birthweight. Some predictors, such as malform and pnumgsa, had most observations coded as 0 and would thus likely have little impact in our model. I only wanted to include the most significant predictors to ensure parsimony.

### fit model with main effects
```{r}
main_effects_model <- lm(bwt ~ blength + gaweeks, data = birthweight_df)

birthweight_df |>
  add_predictions(main_effects_model) |>
  add_residuals(main_effects_model) |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", color = "red") + 
  theme_minimal() +
  labs(x = "Fitted Values", y = "Residuals")
```

### fit model with interactions
```{r}
interaction_model <- lm(bwt ~ bhead * blength * babysex + gaweeks + delwt + smoken + 
                          wtgain + momage + mheight, data = birthweight_df)

birthweight_df |>
  add_predictions(interaction_model) |>
  add_residuals(interaction_model) |>
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(method = "lm", color = "red") + 
  theme_minimal() +
  labs(x = "Fitted Values", y = "Residuals")
```

### make comparisons
```{r}
cv_df <- crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_res_df <- cv_df |> 
  mutate(
    hypothetical_model = map(train, \(x) lm(bwt ~ blength + bhead + gaweeks + delwt + fincome + 
                                              smoken + wtgain + momage + mheight + parity, data = x)),
    main_effects_model = map(train, \(x) lm(bwt ~ blength + gaweeks, data = x)),
    interaction_model = map(train, \(x) lm(bwt ~ bhead * blength * babysex + gaweeks + delwt + smoken + 
                                             wtgain + momage + mheight, data = x))
  ) |> 
  mutate(
    rmse_hypothetical = map2_dbl(hypothetical_model, test, rmse),
    rmse_main_effects = map2_dbl(main_effects_model, test, rmse),
    rmse_interaction = map2_dbl(interaction_model, test, rmse)
  )

cv_res_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  theme_minimal() +
  labs(x = "Model", y = "RMSE")
```

Based on the violin plot, I would choose to use the hypothetical model because it has relatively low RMSE and a fairly consistent distribution of RMSE. The interaction model also has low RMSE, but appears to be distributed less evenly. The main effects only model has quite large RMSE and an uneven distribution.
